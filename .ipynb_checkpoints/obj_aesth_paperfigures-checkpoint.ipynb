{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## install the pytorch3d package; hit 'shift+enter' keys to run\n",
    "!conda create --name pytorch3d --yes\n",
    "!conda activate pytorch3d\n",
    "!python3 -m pip install --upgrade numpy\n",
    "!conda install pytorch torchvision cudatoolkit=10.1 -c pytorch --yes\n",
    "!conda install -c conda-forge -c takatosp1 fvcore --yes\n",
    "!conda install pytorch3d -c pytorch3d --yes\n",
    "!python3 -m pip install tqdm pandas scipy opencv-python \n",
    "!python3 -m pip install --upgrade matplotlib --ignore-installed certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease                        \n",
      "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease              \n",
      "Hit:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease                \n",
      "Hit:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
      "Reading package lists... Done\n",
      "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease                \u001b[0m    \n",
      "Hit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease      \n",
      "Hit:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
      "Hit:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
      "Reading package lists... Done\u001b[0m                \u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "120 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libsm6 is already the newest version (2:1.2.2-1).\n",
      "libxext6 is already the newest version (2:1.3.3-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 120 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libxrender-dev is already the newest version (1:0.9.10-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 120 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libsm6 is already the newest version (2:1.2.2-1).\n",
      "libxext6 is already the newest version (2:1.3.3-1).\n",
      "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 120 not upgraded.\n",
      "Requirement already satisfied: opencv-python in /root/miniconda/lib/python3.8/site-packages (4.4.0.46)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /root/miniconda/lib/python3.8/site-packages (from opencv-python) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt update && apt install -y libsm6 libxext6\n",
    "!apt-get install -y libxrender-dev\n",
    "!apt-get install ffmpeg libsm6 libxext6  -y\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting config\n",
      "getting dataset list\n",
      "Splitting Dataset..\n",
      "/tf/notebooks/acadia2020_graphcnn_src/NamingBookV3_lessthan100kverts.csv\n",
      "getting dataset loader\n",
      "getting dataset split\n",
      "Splitting Dataset..\n",
      "/tf/notebooks/acadia2020_graphcnn_src/NamingBookV3_lessthan100kverts.csv\n",
      "rendering 0\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "!python make_methodsFig1_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## download the concerthall optimization code base; hit 'shift+enter' keys to run\n",
    "#!rm -rf /storage/acadia2020_graphcnn\n",
    "#!git clone https://github.com/alexacarlson/acadia2020_graphcnn.git /storage/acadia2020_graphcnn\n",
    "\n",
    "## check size of dataset/verts etc\n",
    "!python check_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM_SEED: 0\n",
      "DATA:\n",
      "  PATH: /home/alexandracarlson/Desktop/acadia2020_3daesthetics_dataset\n",
      "  SEMCLASS: all\n",
      "  WHICH_TASK: all\n",
      "BASE_MODEL:\n",
      "  CLASSES: 4\n",
      "  CONV_INIT: normal\n",
      "  HIDDEN_DIMS: [128, 256, 512]\n",
      "  INPUT_MESH_FEATS: 3\n",
      "  WHICH_GCN_FN: GraphConvClf3\n",
      "OPTIM:\n",
      "  BATCH_SIZE: 32\n",
      "  CLIP_GRADIENTS: 12.5\n",
      "  EPOCH: 1000\n",
      "  LR: 0.0002\n",
      "  MOMENTUM: 0.9\n",
      "  VAL_BATCH_SIZE: 1\n",
      "  WEIGHT_DECAY: 0.005\n",
      "  WORKERS: 8\n",
      "CHECKPOINT:\n",
      "  best_acc: 0.0\n",
      "  best_loss: 1.7976931348623157e+308\n",
      "  experiment_path: /tf/notebooks/acadia2020_graphcnn_src/acadia2020_graphcnn_training_results/exp_11_24_13_36_09_ai_aesthetics_optim_centered_bs32_lr2e-4_hd128_256_512_alltasks_nettype-GraphConvClf3_class-all\n",
      "  full_experiment_name: exp_11_24_13_36_09_ai_aesthetics_optim_centered_bs32_lr2e-4_hd128_256_512_alltasks_nettype-GraphConvClf3_class-all\n",
      "\n",
      "config_yml          : /tf/notebooks/acadia2020_graphcnn_src/config/mesh2aesthetics_train3.yml\n",
      "config_override     : []\n",
      "Splitting Dataset..\n",
      "/tf/notebooks/acadia2020_graphcnn_src/NamingBookV3_lessthan100kverts.csv\n",
      "number of training samples: 2076\n",
      "Training Samples: 65\n",
      "Validation Samples: 100\n",
      "\n",
      " ***************** Training *****************\n",
      "\n",
      "\t EPOCH 0, totalloss: 29.896, tensor([8.7700e-01, 6.0000e-03, 1.3273e+01, 1.5740e+01])\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy of the network on validation model set STYLE: 69 %\n",
      "Accuracy of the network on validation model set SEMANTIC: 76 %\n",
      "Accuracy of the network on validation model set FUNCTIONALITY: 39 %\n",
      "Accuracy of the network on validation model set AESTHETICS: 27 %\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\t EPOCH 1, totalloss: 29.028, tensor([8.2400e-01, 6.0000e-03, 1.2806e+01, 1.5392e+01])\n",
      "\n",
      "\t EPOCH 2, totalloss: 28.521, tensor([7.9300e-01, 5.0000e-03, 1.2513e+01, 1.5211e+01])\n",
      "\n",
      "\t EPOCH 3, totalloss: 27.989, tensor([7.7500e-01, 4.0000e-03, 1.2296e+01, 1.4913e+01])\n"
     ]
    }
   ],
   "source": [
    "## Train the graph convolutional neural network; hit 'shift+enter' keys to run\n",
    "## NOTES on Training the Graph Convolutional Neural network to map 3D meshes --> aesthetic and functionality parameters:\n",
    "## To train your own graph convolutional network, you first need to create a folder in paperspace storage \n",
    "## at `/storage/concert_dataset` upload your data there. All of your meshes should be `.obj` files and\n",
    "## should exist in a subdirectory of the dataset: `/storage/acadia2020_graphcnn_dataset/Separated/`. \n",
    "## You will need to have a csv file of label/parameters (where each line is in the format `mesh.obj label1 label2 ... label10`) \n",
    "## located at and named `/storage/acadia2020_graphcnn_dataset/NamingBookV2.csv`.\n",
    "## The results (network weights and training loss values) will be saved to `/storage/acadia2020_graphcnn_training_results`.\n",
    "##\n",
    "## Note that this function takes in the absolute filepath of a configuration file (CFG_PATH) that sets up the network architecture.\n",
    "## ## To train on 4 labels:\n",
    "#!cd /storage/acadia2020_graphcnn && bash run_train_graphconv_regression.sh \"/storage/acadia2020_graphcnn/config/mesh2aesthetics_train.yml\"\n",
    "#!cd /tf/notebooks/acadia2020_graphcnn_src && bash run_train_graphconv_regression.sh \"/tf/notebooks/acadia2020_graphcnn_src/config/mesh2aesthetics_train.yml\"\n",
    "\n",
    "#!CUDA_VISIBLE_DEVICES=0 python train_aesthetics.py --config-yml \"/tf/notebooks/acadia2020_graphcnn_src/config/mesh2aesthetics_train.yml\"\n",
    "!CUDA_VISIBLE_DEVICES=0 python train_aesthetics.py --config-yml \"/tf/notebooks/acadia2020_graphcnn_src/config/mesh2aesthetics_train3.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train on single class: house\n",
    "!CUDA_VISIBLE_DEVICES=2 python train_aesthetics.py --config-yml \"/tf/notebooks/acadia2020_graphcnn_src/config/mesh2aesthetics_train_singlesemclass_house.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train on single task: functionality\n",
    "!CUDA_VISIBLE_DEVICES=0 python train_aesthetics.py --config-yml \"/tf/notebooks/acadia2020_graphcnn_src/config/mesh2aesthetics_train_singletask_functionality.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test pretrained network\n",
    "!python test_aesthetics.py --config-yml \"/tf/notebooks/acadia2020_graphcnn_src/config/mesh2aesthetics_test.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run the optimization framework; hit 'shift+enter' keys to run\n",
    "## IMPORTANT INFO about running the acoustic optimization script:\n",
    "## The Command Format for this script: \n",
    "## bash run_acousticoptim.sh INPUT_MESH SILHOUETTE_DEFORM_FLAG SILHOUETTE_REF_IMG ACOUSTIC_DEFORM_FLAG WHICH_ACOUSTIC_PARAMS OUTPUT_NAME\n",
    "## where `INPUT_MESH_FILEPATH` is the absolute filepath of the mesh you would like to deform\n",
    "##       `TRAINED_GRAPH_FILEPATH` is the filepath to the trained mesh2aesthetic graph convolutional neural network\n",
    "##       `STYLE_PARAM` is either 'baroque', 'modern', or 'classic' \n",
    "##       `SEM_PARAM`  is either 'house' or 'column'\n",
    "##       `FUNC_PARAM` is an integer number from [1,2,3,4], where 1 is low functionality and 4 is high functionality\n",
    "##       `AESTH_PARAM` is an integer number from [1,2,3,4], where 1 is poor aesthetics and 5 is good aesthetics \n",
    "##       `OUTPUT_FILENAME` is the absolute filepath where you would like the deformed output mesh to be saved.\n",
    "##       `NUM_ITERS` is the number of iterations to run the optimization.\n",
    "##       `CFG_FILE` is the absolute path to the configuration file. You will need to change this to the config file path that you used for training the model (see above cell)\n",
    "##\n",
    "## Example Command:\n",
    "#!cd /storage/concerthall && bash run_acousticoptim.sh \\\n",
    "#                            INPUT_MESH_FILEPATH \\\n",
    "#                            TRAINED_GRAPH_FILEPATH \\\n",
    "#                            STYLE_PARAM \\\n",
    "#                            SEM_PARAM \\\n",
    "#                            FUNC_PARAM \\\n",
    "#                            AESTH_PARAM \\\n",
    "#                            OUTPUT_FILENAME \\\n",
    "#                            NUM_ITERS \\\n",
    "#                            CFG_FILE\n",
    "#\n",
    "!cd /storage/acadia2020_graphcnn && bash run_param_optim.sh \\\n",
    "                            \"/storage/3Dmodels/bench.obj\" \\\n",
    "                            \"/storage/acadia2020_graphcnn_training_results/exp_09_26_14_01_06_ai_aesthetics_optim/model_best_loss.pkl\" \\\n",
    "                            \"modern\" \\\n",
    "                            \"house\" \\\n",
    "                            4 \\\n",
    "                            5 \\\n",
    "                            \"test_sil_deform.obj\" \\\n",
    "                            250 \\\n",
    "                            \"/storage/acadia2020_graphcnn/config/mesh2aesthetics_train.yml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
