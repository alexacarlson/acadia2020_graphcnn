{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## install the pytorch3d package; hit 'shift+enter' keys to run\n",
    "!conda create --name pytorch3d --yes\n",
    "!conda activate pytorch3d\n",
    "!python3 -m pip install --upgrade numpy\n",
    "!conda install pytorch torchvision cudatoolkit=10.1 -c pytorch --yes\n",
    "!conda install -c conda-forge -c takatosp1 fvcore --yes\n",
    "!conda install pytorch3d -c pytorch3d --yes\n",
    "!python3 -m pip install tqdm pandas scipy opencv-python \n",
    "!python3 -m pip install --upgrade matplotlib --ignore-installed certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## download the concerthall optimization code base; hit 'shift+enter' keys to run\n",
    "#!rm -rf /storage/acadia2020_graphcnn\n",
    "#!git clone https://github.com/alexacarlson/acadia2020_graphcnn.git /storage/acadia2020_graphcnn\n",
    "\n",
    "## check size of dataset/verts etc\n",
    "!python check_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the graph convolutional neural network; hit 'shift+enter' keys to run\n",
    "## NOTES on Training the Graph Convolutional Neural network to map 3D meshes --> aesthetic and functionality parameters:\n",
    "## To train your own graph convolutional network, you first need to create a folder in paperspace storage \n",
    "## at `/storage/concert_dataset` upload your data there. All of your meshes should be `.obj` files and\n",
    "## should exist in a subdirectory of the dataset: `/storage/acadia2020_graphcnn_dataset/Separated/`. \n",
    "## You will need to have a csv file of label/parameters (where each line is in the format `mesh.obj label1 label2 ... label10`) \n",
    "## located at and named `/storage/acadia2020_graphcnn_dataset/NamingBookV2.csv`.\n",
    "## The results (network weights and training loss values) will be saved to `/storage/acadia2020_graphcnn_training_results`.\n",
    "##\n",
    "## Note that this function takes in the absolute filepath of a configuration file (CFG_PATH) that sets up the network architecture.\n",
    "## ## To train on 4 labels:\n",
    "#!cd /storage/acadia2020_graphcnn && bash run_train_graphconv_regression.sh \"/storage/acadia2020_graphcnn/config/mesh2aesthetics_train.yml\"\n",
    "#!cd /tf/notebooks/acadia2020_graphcnn_src && bash run_train_graphconv_regression.sh \"/tf/notebooks/acadia2020_graphcnn_src/config/mesh2aesthetics_train.yml\"\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=1 python train_aesthetics.py --config-yml \"/tf/notebooks/acadia2020_graphcnn_src/config/mesh2aesthetics_train2.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM_SEED: 0\n",
      "DATA:\n",
      "  PATH: /home/alexandracarlson/Desktop/acadia2020_3daesthetics_dataset\n",
      "  SEMCLASS: column\n",
      "  WHICH_TASK: all\n",
      "BASE_MODEL:\n",
      "  CLASSES: 4\n",
      "  CONV_INIT: normal\n",
      "  HIDDEN_DIMS: [128, 128, 256, 256, 512]\n",
      "  INPUT_MESH_FEATS: 3\n",
      "  WHICH_GCN_FN: GraphConvClf_singlesemclass\n",
      "OPTIM:\n",
      "  BATCH_SIZE: 32\n",
      "  CLIP_GRADIENTS: 12.5\n",
      "  EPOCH: 2500\n",
      "  LR: 0.0002\n",
      "  MOMENTUM: 0.9\n",
      "  VAL_BATCH_SIZE: 1\n",
      "  WEIGHT_DECAY: 0.005\n",
      "  WORKERS: 8\n",
      "CHECKPOINT:\n",
      "  best_acc: 0.0\n",
      "  best_loss: 1.7976931348623157e+308\n",
      "  experiment_path: /tf/notebooks/acadia2020_graphcnn_src/acadia2020_graphcnn_training_results/exp_11_23_10_08_39_ai_aesthetics_optim_nettype-GraphConvClf_singlesemclass_class-column\n",
      "  full_experiment_name: exp_11_23_10_08_39_ai_aesthetics_optim_nettype-GraphConvClf_singlesemclass_class-column\n",
      "\n",
      "config_yml          : /tf/notebooks/acadia2020_graphcnn_src/config/mesh2aesthetics_train_singlesemclass_column.yml\n",
      "config_override     : []\n",
      "Splitting Dataset..\n",
      "number of training samples: 1511\n",
      "Training Samples: 48\n",
      "Validation Samples: 50\n",
      "\n",
      " ***************** Training *****************\n",
      "Traceback (most recent call last):\n",
      "  File \"train_aesthetics.py\", line 177, in <module>\n",
      "    outputs = model(mesh)\n",
      "  File \"/root/miniconda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/tf/notebooks/acadia2020_graphcnn_src/style_transfer/models/base_nn.py\", line 187, in forward\n",
      "    verts = getattr(self, 'gconv{}'.format(i))(verts, edges)\n",
      "  File \"/root/miniconda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/root/miniconda/lib/python3.8/site-packages/pytorch3d/ops/graph_conv.py\", line 81, in forward\n",
      "    out = verts_w0 + neighbor_sums\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 724.00 MiB (GPU 0; 7.93 GiB total capacity; 6.44 GiB already allocated; 416.88 MiB free; 6.93 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "## train on single class: columns\n",
    "!CUDA_VISIBLE_DEVICES=1 python train_aesthetics.py --config-yml \"/tf/notebooks/acadia2020_graphcnn_src/config/mesh2aesthetics_train_singlesemclass_column.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test pretrained network\n",
    "!python test_aesthetics.py --config-yml \"/tf/notebooks/acadia2020_graphcnn_src/config/mesh2aesthetics_test.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run the optimization framework; hit 'shift+enter' keys to run\n",
    "## IMPORTANT INFO about running the acoustic optimization script:\n",
    "## The Command Format for this script: \n",
    "## bash run_acousticoptim.sh INPUT_MESH SILHOUETTE_DEFORM_FLAG SILHOUETTE_REF_IMG ACOUSTIC_DEFORM_FLAG WHICH_ACOUSTIC_PARAMS OUTPUT_NAME\n",
    "## where `INPUT_MESH_FILEPATH` is the absolute filepath of the mesh you would like to deform\n",
    "##       `TRAINED_GRAPH_FILEPATH` is the filepath to the trained mesh2aesthetic graph convolutional neural network\n",
    "##       `STYLE_PARAM` is either 'baroque', 'modern', or 'classic' \n",
    "##       `SEM_PARAM`  is either 'house' or 'column'\n",
    "##       `FUNC_PARAM` is an integer number from [1,2,3,4], where 1 is low functionality and 4 is high functionality\n",
    "##       `AESTH_PARAM` is an integer number from [1,2,3,4], where 1 is poor aesthetics and 5 is good aesthetics \n",
    "##       `OUTPUT_FILENAME` is the absolute filepath where you would like the deformed output mesh to be saved.\n",
    "##       `NUM_ITERS` is the number of iterations to run the optimization.\n",
    "##       `CFG_FILE` is the absolute path to the configuration file. You will need to change this to the config file path that you used for training the model (see above cell)\n",
    "##\n",
    "## Example Command:\n",
    "#!cd /storage/concerthall && bash run_acousticoptim.sh \\\n",
    "#                            INPUT_MESH_FILEPATH \\\n",
    "#                            TRAINED_GRAPH_FILEPATH \\\n",
    "#                            STYLE_PARAM \\\n",
    "#                            SEM_PARAM \\\n",
    "#                            FUNC_PARAM \\\n",
    "#                            AESTH_PARAM \\\n",
    "#                            OUTPUT_FILENAME \\\n",
    "#                            NUM_ITERS \\\n",
    "#                            CFG_FILE\n",
    "#\n",
    "!cd /storage/acadia2020_graphcnn && bash run_param_optim.sh \\\n",
    "                            \"/storage/3Dmodels/bench.obj\" \\\n",
    "                            \"/storage/acadia2020_graphcnn_training_results/exp_09_26_14_01_06_ai_aesthetics_optim/model_best_loss.pkl\" \\\n",
    "                            \"modern\" \\\n",
    "                            \"house\" \\\n",
    "                            4 \\\n",
    "                            5 \\\n",
    "                            \"test_sil_deform.obj\" \\\n",
    "                            250 \\\n",
    "                            \"/storage/acadia2020_graphcnn/config/mesh2aesthetics_train.yml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
